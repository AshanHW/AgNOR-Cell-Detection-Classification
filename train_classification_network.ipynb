{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EfficientNet B0 Network for the AgNOR classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.optim as optim\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from torchmetrics import Accuracy, F1Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Dataset class\n",
    "\n",
    "We have a total of 27 images (1973 annotaions), which is significantly small amount of data. There is a huge imbalance in the dataset that classes o,1,2 are over-represented. Also, we need to split these data into train, validation & test datasets.\n",
    "\n",
    "Therefore, we come with oversampling method as a solution for the class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, df, transform, num_samples=1000):\n",
    "        self.df = df\n",
    "        self.num_samples = num_samples\n",
    "        self.transform = transform\n",
    "        self.sampled_df = self.init_samples()\n",
    "        self.df = self.sampled_df\n",
    "\n",
    "\n",
    "    def init_samples(self):\n",
    "\n",
    "        classes = self.df.label.unique()\n",
    "        returnclass = np.random.choice(classes, self.num_samples)\n",
    "        out = []\n",
    "\n",
    "        for cl in returnclass:\n",
    "            out.append(df.query(f\"label == {cl}\").sample(1))\n",
    "\n",
    "        sampled_df = pd.concat(out)\n",
    "        \n",
    "        return sampled_df\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sampled_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        row = self.df.iloc[idx]\n",
    "        max_x = row['max_x']\n",
    "        max_y = row['max_y']\n",
    "        min_x = row['min_x']\n",
    "        min_y = row['min_y']\n",
    "        imgname = row['filename']\n",
    "        label = row['label']\n",
    "\n",
    "        fullimage = Image.open(imgname).convert('RGB')\n",
    "        img = fullimage.crop(((min_x, min_y, max_x, max_y)))\n",
    "        \n",
    "        img = self.transform(img)\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmentation Methods\n",
    "\n",
    "We also need a solution for limited number of images/annotaions. The best way out is to add more images. Unfortunately, it is out of the equation. Hence, we introduce data augmentation methods, namely Gaussian blur, Colorjitter to overcome this problem.\n",
    "\n",
    "We have fixed crop size to be fed into our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gaussian:\n",
    "    def __init__(self, kernelsize = (3,3)):\n",
    "        self.kernel_size = kernelsize\n",
    "\n",
    "    def __call__(self, image):\n",
    "        image = np.array(image)\n",
    "        filteredimg = cv2.GaussianBlur(image, self.kernel_size, 0)\n",
    "        return Image.fromarray(filteredimg)\n",
    "    \n",
    "\n",
    "\n",
    "class Colorjitter:\n",
    "    def __init__(self, brightness=0, contrast=0, saturation=0):\n",
    "        self.brightness = brightness\n",
    "        self.contrast = contrast\n",
    "        self.saturation = saturation\n",
    "\n",
    "\n",
    "    def differ_brightness(self, image):\n",
    "        image = image + 255 * self.brightness\n",
    "        return np.clip(image, 0, 255).astype(np.uint8)\n",
    "    \n",
    "\n",
    "    def differ_contrast(self, image):\n",
    "        meanvalue = np.mean(image, axis=(0,1), keepdims=True)\n",
    "        image = (image - meanvalue) * self.contrast + meanvalue\n",
    "        return np.clip(image, 0, 255).astype(np.uint8)\n",
    "\n",
    "\n",
    "    def differ_saturation(self, image):\n",
    "        gray = np.mean(image, axis=2, keepdims=True)\n",
    "        image = image * (1 + self.saturation) + gray * self.saturation\n",
    "        return np.clip(image, 0, 255).astype(np.uint8)\n",
    "    \n",
    "\n",
    "    def __call__(self, image):\n",
    "        image = np.array(image)\n",
    "        image = self.differ_brightness(image)\n",
    "        image = self.differ_contrast(image)\n",
    "        image = self.differ_saturation(image)\n",
    "        return image\n",
    "    \n",
    "\n",
    "mytransform = transforms.Compose([\n",
    "    transforms.Resize((50,50)),\n",
    "    transforms.Lambda(Gaussian()),\n",
    "    transforms.Lambda(Colorjitter()),\n",
    "    transforms.ToTensor()\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Raw Data & make Dataloaders\n",
    "\n",
    "train 70 % , Validation 15 %, Test 15 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dataset = pd.read_csv('annotation_frame.csv')\n",
    "\n",
    "\n",
    "# train 70 % , Validation 15 %, Test 15 %\n",
    "traindata, testdata = train_test_split(my_dataset, test_size=0.3, random_state=56)\n",
    "validata, testdata = train_test_split(testdata, test_size=0.5, random_state=56)\n",
    "\n",
    "train_dataset = MyDataset(traindata, transform=mytransform)\n",
    "val_dataset = MyDataset(validata, transform=mytransform)\n",
    "test_dataset = MyDataset(testdata, transform=mytransform)\n",
    "\n",
    "trainloader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "valiloader = DataLoader(val_dataset, batch_size=4, shuffle=False)\n",
    "testloader = DataLoader(test_dataset, batch_size=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialising the model\n",
    "\n",
    "For this task, we have used EfficientNet B0 model as the classifier. Model's backbone is frozen. Output layer is changed to 12 classes to match our task. So that we only need to train weights for the output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = efficientnet_b0(weights='IMAGENET1K_V1')\n",
    "\n",
    "#print(model)\n",
    "\n",
    "\n",
    "# Freezing layers\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "classes = 12\n",
    "model.classifier[-1] = torch.nn.Linear(in_features=1280, out_features=classes)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function & Optimizer\n",
    "\n",
    "Cross Entrophy loss is a convex loss function which commonly used in neural networks.\n",
    "\n",
    "The loss function is combined with Adam optimzer to update weights and biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training & Validation Loops\n",
    "\n",
    "Accuracy score from torchmetrics is used to evaluate models in validation phase. The model with lowest validation loss is saved in the disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, dataloader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for inputs, labels in tqdm(dataloader, desc='Training'):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        # making gradients zero\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass\n",
    "        outputs = model(inputs)\n",
    "        # calculate loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        #back propagation\n",
    "        loss.backward()\n",
    "        # updating parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "    \n",
    "    epoch_loss = running_loss / len(dataloader.dataset)\n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_one_epoch(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    accuracy = Accuracy(task='multiclass', num_classes=12).to(device)\n",
    "    accuracy.reset()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(dataloader, desc='Validation'):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "            accuracy.update(outputs, labels)\n",
    "\n",
    "    epoch_loss = val_loss / len(dataloader.dataset)\n",
    "    acc = accuracy.compute()\n",
    "    return epoch_loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_epochs(model, trainloader, valiloader, optimizer, criterion, device, num_epochs=50):\n",
    "    best_val_loss = float('inf')\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "        \n",
    "        # Training\n",
    "        train_loss = train_one_epoch(model, trainloader, optimizer, criterion, device)\n",
    "        train_losses.append(train_loss)\n",
    "        print(f\"Training Loss: {train_loss}\")\n",
    "\n",
    "        # Validation\n",
    "        val_loss, val_acc = validate_one_epoch(model, valiloader, criterion, device)\n",
    "        val_losses.append(val_loss)\n",
    "        val_accuracies.append(val_acc)\n",
    "        print(f\"Validation Loss: {val_loss}, Validation Accuracy: {val_acc}\")\n",
    "\n",
    "        # Best model\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), 'best_model_cl.pth')\n",
    "\n",
    "    return train_losses, val_losses, val_accuracies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses, val_losses, val_accuracies = n_epochs(model, trainloader, valiloader, optimizer, criterion, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualising Tr_Loss & Vl_Loss over epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Losses')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing\n",
    "\n",
    "F1 score is used to evaluate the final model we saved from training. Here, we can grasp how well the model predicts, generalise and etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = efficientnet_b0(weights=None)\n",
    "best_model.classifier[-1] = torch.nn.Linear(in_features=1280, out_features=classes)\n",
    "best_model.load_state_dict(torch.load('best_model_cl.pth'))\n",
    "best_model.to(device)\n",
    "best_model.eval()\n",
    "\n",
    "f1_score = F1Score(num_classes=classes, task=\"multiclass\").to(device)\n",
    "\n",
    "def test_model(model, testloader, device, metric):\n",
    "    metric.reset()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(testloader, desc='Testing'):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            metric.update(outputs, labels)\n",
    "\n",
    "    f1 = metric.compute()\n",
    "    return f1\n",
    "\n",
    "\n",
    "f1 = test_model(best_model, testloader, device, f1_score )\n",
    "print(f\"F1 score is :{f1}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
